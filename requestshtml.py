#Python Tutorial Web Scraping with Requests-HTML
from requests_html import HTML, HTMLSession
import csv

#Open HTML file and pass HTML contents into HTML class.  Parse HTML directly.
with open("simple.html", "r") as htmlfile:
    source = htmlfile.read()
    htmlcode = HTML(html=source)
# print(htmlcode.html)
'''
<!doctype html>
<html class="no-js" lang="">
    <head>
        <title>Test - A Sample Website</title>
        <meta charset="utf-8">
        <link rel="stylesheet" href="css/normalize.css">
        <link rel="stylesheet" href="css/main.css">
    </head>
    <body>
        <h1 id='site_title'>Test Website</h1>
        <hr></hr>
        <div class="article">
            <h2><a href="article_1.html">Article 1 Headline</a></h2>
            <p>This is a summary of article 1</p>
        </div>
...
'''
print(htmlcode.text)
'''
Test - A Sample Website
Test Website
Article 1 Headline
This is a summary of article 1
'''
title = htmlcode.find("title")
print(title) #print [<Element 'title' >]
print(type(title)) #print <class 'list'>
print(title[0]) #print <Element 'title' >
print(title[0].html) #print <title>Test - A Sample Website</title>
print(title[0].text) #print Test - A Sample Website
firstfindtitle = htmlcode.find("title", first=True)
print(firstfindtitle) #print <Element 'title' >
print(type(firstfindtitle)) #print <class 'requests_html.Element'>
print(firstfindtitle.text) #print Test - A Sample Website
firstfindfooterdivid = htmlcode.find("#footer", first=True) #<div id='footer'>
print(firstfindfooterdivid) #print <Element 'div' id='footer'>
print(firstfindfooterdivid.text) #print Footer Information
articleclass = htmlcode.find("div.article", first=True)
print(articleclass.text) #print Article 1 Headline\n This is a summary of article 1
articleclassheadline = articleclass.find("h2", first=True)
print(articleclassheadline.text) #print Article 1 Headline
articleclasssummary = articleclass.find("p", first=True).text
print(articleclasssummary) #print This is a summary of article 1
allarticleclasses = htmlcode.find("div.article")
print(allarticleclasses) #print [<Element 'div' class=('article',)>, <Element 'div' class=('article',)>]
for eachallarticleclasses in allarticleclasses:
    print(eachallarticleclasses) #print <Element 'div' class=('article',)>
    #articleclassheadline = eachallarticleclasses.find("h2")
    #print(articleclassheadline.text) #print AttributeError: 'list' object has no attribute 'text'
    articleclassheadline = eachallarticleclasses.find("h2", first=True)
    print(articleclassheadline.text) #print Article 1 Headline
    #articleclasssummary = eachallarticleclasses.find("p").text
    #print(articleclasssummary) #print AttributeError: 'list' object has no attribute 'text'
    articleclasssummary = eachallarticleclasses.find("p", first=True).text
    print(articleclasssummary) #print This is a summary of article 1
#Display HTML from JavaScript code.
with open("simple.html") as htmlfile:
    source = htmlfile.read()
    htmlcode = HTML(html=source)
    htmlcode.render()
match = htmlcode.find("#footer", first=True)
print(match.html)
'''
Before htmlcode.render()
<div id="footer">
<p>Footer Information</p>
</div>
'''
'''
htmlcode.render()
<div id="footer">
<p>Footer Information</p>
<p>This is text generated by JavaScript.</p></div>
'''

#Web scrape a webpage
session = HTMLSession()
response = session.get("https://coreyms.com/")  #HTML requests library to get a response from a website; response is the webpage as an object.
print(response.html) #print <HTML url='https://coreyms.com/'>
articleclass = response.html.find("article", first=True)
print(articleclass) #print <Element 'article' class=('post-1670', 'post', 'type-post', 'status-publish', 'format-standard', 'has-post-thumbnail', 'category-development', 'category-python', 'tag-gzip', 'tag-shutil', 'tag-zip', 'tag-zipfile', 'entry') itemscope='' itemtype='https://schema.org/CreativeWork'>
print(articleclass.html)
'''
<article class="post-1670 post type-post status-publish format-standard has-post-thumbnail category-development category-python tag-gzip tag-shutil tag-zip tag-zipfile entry" itemscope="" itemtype="https://schema.org/CreativeWork"><header class="entry-header"><h2 class="entry-title" itemprop="headline"><a class="entry-title-link" rel="bookmark" href="https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives">Python Tutorial: Zip Files – Creating and Extracting Zip Archives</a></h2>
<p class="entry-meta"><time class="entry-time" itemprop="datePublished" datetime="2019-11-19T13:02:37-05:00">November 19, 2019</time> by <span class="entry-author" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><a href="https://coreyms.com/author/coreymschafer" class="entry-author-link" itemprop="url" rel="author"><span class="entry-author-name" itemprop="name">Corey Schafer</span></a></span> <span class="entry-comments-link"><a href="https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives#respond"><span class="dsq-postid" data-dsqidentifier="1670 http://coreyms.com/?p=1670">Leave a Comment</span></a></span> </p></header><div class="entry-content" itemprop="text">
<p>In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…<br/></p>
<span class="embed-youtube" style="text-align:center; display: block;"><iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/z0gguhEmWiY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true" style="border:0;"/></span>
</div><footer class="entry-footer"><p class="entry-meta"><span class="entry-categories">Filed Under: <a href="https://coreyms.com/category/development" rel="category tag">Development</a>, <a href="https://coreyms.com/category/development/python" rel="category tag">Python</a></span> <span class="entry-tags">Tagged With: <a href="https://coreyms.com/tag/gzip" rel="tag">gzip</a>, <a href="https://coreyms.com/tag/shutil" rel="tag">shutil</a>, <a href="https://coreyms.com/tag/zip" rel="tag">zip</a>, <a href="https://coreyms.com/tag/zipfile" rel="tag">zipfile</a></span></p></footer></article>
'''
headline = articleclass.find(".entry-title-link", first=True).text
print(headline) #print Python Tutorial: Zip Files – Creating and Extracting Zip Archives
'''
also works
articleclass2 = response.html.find("article", first=True).find(".entry-title-link", first=True).text
print(articleclass2) #print Python Tutorial: Zip Files – Creating and Extracting Zip Archives
'''
summary = articleclass.find(".entry-content p", first=True).text #The find method uses CSS selectors in requests_html module.
print(summary) #print In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…
youtubevideo = articleclass.find("iframe", first=True)
print(youtubevideo.html) #print <iframe class="youtube-player" width="640" height="360" src="https://www.youtube.com/embed/z0gguhEmWiY?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent" allowfullscreen="true" style="border:0;"/>
print(type(youtubevideo.html)) #print <class 'str'>
print(youtubevideo.attrs) #print {'class': ('youtube-player',), 'width': '640', 'height': '360', 'src': 'https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent', 'allowfullscreen': 'true', 'style': 'border:0;'}
print(type(youtubevideo.attrs)) #print <class 'dict'>
print(youtubevideo.attrs["src"]) #print https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent
youtubevideo = articleclass.find("iframe", first=True).attrs["src"]
print(youtubevideo) #print https://www.youtube.com/embed/z0gguhEmWiY?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent
print(youtubevideo.find("?")) #print 41
print(youtubevideo[0:youtubevideo.find("?")]) #print https://www.youtube.com/embed/z0gguhEmWiY
youtubevideo = articleclass.find("iframe", first=True).attrs["src"][0:youtubevideo.find("?")]
print(youtubevideo) #print https://www.youtube.com/embed/z0gguhEmWiY
print(youtubevideo.replace("embed/", "watch?v=")) #print https://www.youtube.com/watch?v=z0gguhEmWiY
#For loop web scrape all desired HTML content
csvfile = open("cmsscrape.csv", "w")
csvwriter = csv.writer(csvfile)
csvwriter.writerow(["headline", "summary", "video"])
allarticleclass = response.html.find("article")
for eachallarticleclasses in allarticleclass:
    headline = eachallarticleclasses.find(".entry-title-link", first=True).text
    print(headline)
    summary = eachallarticleclasses.find(".entry-content p", first=True).text #The find method uses CSS selectors in requests_html module.
    print(summary)
    try:
        youtubevideosource = eachallarticleclasses.find("iframe", first=True).attrs["src"]
        youtubevideo = eachallarticleclasses.find("iframe", first=True).attrs["src"][0:youtubevideosource.find("?version=")].replace("embed/", "watch?v=")
        print(youtubevideo)
    except AttributeError:
        youtubevideo = None
    print("\n")
    '''
    Python Tutorial: Zip Files – Creating and Extracting Zip Archives
    In this video, we will be learning how to create and extract zip archives. We will start by using the zipfile module, and then we will see how to do this using the shutil module. We will learn how to do this with single files and directories, as well as learning how to use gzip as well. Let’s get started…
    https://www.youtube.com/watch?v=z0gguhEmWiY


    Python Data Science Tutorial: Analyzing the 2019 Stack Overflow Developer Survey
    In this Python Programming video, we will be learning how to download and analyze real-world data from the 2019 Stack Overflow Developer Survey. This is terrific practice for anyone getting into the data science field. We will learn different ways to analyze this data and also some best practices. Let’s get started…
    https://www.youtube.com/watch?v=_P7X8tMplsw
    ...
    '''
    csvwriter.writerow([headline, summary, youtubevideo])
csvfile.close()

#Get all links
session = HTMLSession()
response = session.get("https://coreyms.com/")  #HTML requests library to get a response from a website; response is the webpage as an object.
print(type(response.html.links)) #print <class 'set'>
print(response.html.links)
'''
{'https://coreyms.com/giveaway', 'https://coreyms.com/contributors', 'https://coreyms.com/', 'https://coreyms.com/development/python/python-quick-tip-the-difference-between-and-is-equality-vs-identity#respond', 'https://coreyms.com/tag/mutable-default-arguments', 'https://coreyms.com/development/python/python-tutorial-calling-external-commands-using-the-subprocess-module', 'https://plus.google.com/+CoreySchafer44/posts', 'https://coreyms.com/category/web-design', 'https://coreyms.com/tag/multiprocessing', 'https://coreyms.com/development/python/python-data-science-tutorial-analyzing-the-2019-stack-overflow-developer-survey', 'http://coreyms.com/portfolio', 'https://coreyms.com/development/python/visual-studio-code-windows-setting-up-a-python-development-environment-and-complete-overview#respond', 'https://coreyms.com/page/3', 'https://coreyms.com/category/development/git', 'https://coreyms.com/development/python/visual-studio-code-windows-setting-up-a-python-development-environment-and-complete-overview', 'https://coreyms.com/category/diy/home-improvement', 'https://coreyms.com/category/diy', 'https://coreyms.com/tag/data-science', 'http://www.startalkradio.net/shows-archive/', 'https://coreyms.com/tag/standard-library', 'http://www.se-radio.net/', 'https://coreyms.com/tag/functions', 'https://coreyms.com/category/web-design/css', 'http://coreyms.com/feed/', 'https://coreyms.com/development/python/python-tutorial-zip-files-creating-and-extracting-zip-archives#respond', 'https://www.amazon.com/gp/product/0984782850/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=0984782850&linkCode=as2&tag=coreyms-20&linkId=e2f7c21906426f17958a1d04718e7d02', 'https://www.amazon.com/gp/product/1449355730/ref=as_li_tl?ie=UTF8&camp=1789&creative=9325&creativeASIN=1449355730&linkCode=as2&tag=coreyms-20&linkId=2f9ceaf471d7d35f2c2657051780fc6f', 'https://coreyms.com/development/python/python-multiprocessing-tutorial-run-code-in-parallel-using-the-multiprocessing-module#respond', 'https://coreyms.com/tag/zipfile', 'https://coreyms.com/tag/identity', 'https://coreyms.com/development/python/clarifying-the-issues-with-mutable-default-arguments#respond', 'https://coreyms.com/category/diy/woodworking', 'http://coreyms.com', 'https://blog.codepen.io/radio/', 'https://coreyms.com/tag/concurrency', 'https://www.youtube.com/user/schafer5', 'http://www.samharris.org/podcast',
'''
for eachlink in response.html.links:
    print(eachlink)
    '''
    https://coreyms.com/giveaway
    https://coreyms.com/contributors
    https://coreyms.com/
    https://coreyms.com/development/python/python-quick-tip-the-difference-between-and-is-equality-vs-identity#respond
    https://coreyms.com/tag/mutable-default-arguments
    https://coreyms.com/development/python/python-tutorial-calling-external-commands-using-the-subprocess-module
    https://plus.google.com/+CoreySchafer44/posts
    '''
print("\n")
for eachlink in response.html.absolute_links: #prints absolute links
    print(eachlink)
    '''
    https://coreyms.com/giveaway
    https://coreyms.com/contributors
    https://coreyms.com/
    https://coreyms.com/development/python/python-quick-tip-the-difference-between-and-is-equality-vs-identity#respond
    https://coreyms.com/tag/mutable-default-arguments
    https://coreyms.com/development/python/python-tutorial-calling-external-commands-using-the-subprocess-module
    https://plus.google.com/+CoreySchafer44/posts
    '''

#Python Requests Tutorial Request Web Pages, Download Images, POST Data, Read JSON, and More
import requests
'''
webpagerequest = requests.get("https://xkcd.com/353/")
print(webpagerequest) #print <Response [200]>
print(dir(webpagerequest)) #print ['__attrs__', '__bool__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__enter__', '__eq__', '__exit__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__iter__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__nonzero__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_content', '_content_consumed', '_next', 'apparent_encoding', 'close', 'connection', 'content', 'cookies', 'elapsed', 'encoding', 'headers', 'history', 'is_permanent_redirect', 'is_redirect', 'iter_content', 'iter_lines', 'json', 'links', 'next', 'ok', 'raise_for_status', 'raw', 'reason', 'request', 'status_code', 'text', 'url']  #RM:  prints attributes and methods
#print(help(webpagerequest)) #press q to exit
print(dir(print)) #print ['__call__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__name__', '__ne__', '__new__', '__qualname__', '__reduce__', '__reduce_ex__', '__repr__', '__self__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__text_signature__']
print(webpagerequest.text) #prints the webpage html code
print(webpagerequest.status_code) #print 200
print(webpagerequest.ok) #print True.  .ok prints True for status code numbers less than 400.
print(webpagerequest.headers) #print {'Connection': 'keep-alive', 'Content-Length': '2861', 'Server': 'nginx', 'Content-Type': 'text/html; charset=UTF-8', 'Last-Modified': 'Fri, 31 Jul 2020 04:00:05 GMT', 'ETag': 'W/"5f239745-1bb9"', 'Expires': 'Sat, 01 Aug 2020 20:47:12 GMT', 'Cache-Control': 'max-age=300', 'Content-Encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Date': 'Sat, 01 Aug 2020 21:18:15 GMT', 'Via': '1.1 varnish', 'Age': '149', 'X-Served-By': 'cache-pao17427-PAO', 'X-Cache': 'HIT', 'X-Cache-Hits': '1', 'X-Timer': 'S1596316695.305503,VS0,VE1', 'Vary': 'Accept-Encoding'}
'''
#Get parameters
payload = {"page": 2, "count": 25}
webpagerequest = requests.get("https://httpbin.org/get", params=payload)
print(webpagerequest.text)
'''
{
  "args": {
    "count": "25", 
    "page": "2"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.22.0", 
    "X-Amzn-Trace-Id": "Root=1-5f25ddbf-182c86c097969680240980c0"
  }, 
  "origin": "172.7.144.90", 
  "url": "https://httpbin.org/get?page=2&count=25"
}
'''
print(webpagerequest.url) #print https://httpbin.org/get?page=2&count=25
#Post parameters
payload = {"username": "corey", "password": "testing"}
usernamepasswordwebpagerequest = requests.post("https://httpbin.org/post", data=payload)
print(usernamepasswordwebpagerequest.text)
'''
{
  "args": {}, 
  "data": "", 
  "files": {}, 
  "form": {
    "password": "testing", 
    "username": "corey"
  }, 
  "headers": {
    "Accept": "*/*", 
    "Accept-Encoding": "gzip, deflate", 
    "Content-Length": "31", 
    "Content-Type": "application/x-www-form-urlencoded", 
    "Host": "httpbin.org", 
    "User-Agent": "python-requests/2.22.0", 
    "X-Amzn-Trace-Id": "Root=1-5f25de84-41aa1642f489d7824f85fe82"
  }, 
  "json": null, 
  "origin": "172.7.144.90", 
  "url": "https://httpbin.org/post"
}
'''
print(usernamepasswordwebpagerequest.json())
'''
{'args': {}, 'data': '', 'files': {}, 'form': {'password': 'testing', 'username': 'corey'}, 'headers': {'Accept': '*/*', 'Accept-Encoding': 'gzip, deflate', 'Content-Length': '31', 'Content-Type': 'application/x-www-form-urlencoded', 'Host': 'httpbin.org', 'User-Agent': 'python-requests/2.22.0', 'X-Amzn-Trace-Id': 'Root=1-5f25df05-1482c4660b2f032860fc0106'}, 'json': None, 'origin': '172.7.144.90', 'url': 'https://httpbin.org/post'}
'''
webpagerequestdictionary = usernamepasswordwebpagerequest.json()
print(webpagerequestdictionary["form"]) #print {'password': 'testing', 'username': 'corey'}
passwordwebpagerequest = requests.get("https://httpbin.org/basic-auth/corey/testing", auth=("corey", "testing")) #corey is user name, testing is password
print(passwordwebpagerequest) #print <Response [200]>
print(passwordwebpagerequest.text)
'''
{
  "authenticated": true, 
  "user": "corey"
}
'''
delaywebpagerequest = requests.get("https://httpbin.org/delay/1", timeout=3)
print(delaywebpagerequest) #print <Response [200]>
# delaywebpagerequest = requests.get("https://httpbin.org/delay/6", timeout=3)
# print(delaywebpagerequest) #print socket.timeout: The read operation timed out

#Download an image
imagerequest = requests.get("https://imgs.xkcd.com/comics/python.png")
#print(imagerequest.content) #prints the bytes from the image
with open("comic.png", "wb") as imagefile: #wb is write bytes
    imagefile.write(imagerequest.content)
